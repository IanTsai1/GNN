{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0664ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "#!pip install torch-geometric\n",
    "from torch_geometric.data import Data\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.nn import Embedding\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98477f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_dict = np.load(\"data/gnn_data.npy\",allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126c1b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#key = \"open alex id\", value = [embedding, citation relationship array, subtopic, primary topic, github url, institution, year]\n",
    "repository_dict.keys()\n",
    "len(repository_dict['W2963873275'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b1be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "\n",
    "topics = [value[3] for value in repository_dict.values()]       # Primary topic (One-Hot Encoding)\n",
    "subtopics = [value[2] for value in repository_dict.values()]    # Subtopic (Embedding)\n",
    "institutions = [value[5] for value in repository_dict.values()] # Institution (Embedding)\n",
    "\n",
    "#One-Hot Encoding for 'topic' (Assuming 2 unique values, e.g., \"topic_A\", \"topic_B\")\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "topics_encoded = onehot_encoder.fit_transform(np.array(topics).reshape(-1, 1))\n",
    "\n",
    "#Embedding Encoding for 'subtopic' (46 unique values) and 'institution' (56 unique values)\n",
    "\n",
    "subtopic_to_index = {sub: idx for idx, sub in enumerate(set(subtopics))}\n",
    "institution_to_index = {inst: idx for idx, inst in enumerate(set(institutions))}\n",
    "\n",
    "subtopic_indices = [subtopic_to_index[sub] for sub in subtopics]\n",
    "institution_indices = [institution_to_index[inst] for inst in institutions]\n",
    "\n",
    "subtopic_embedding_dim = 16\n",
    "institution_embedding_dim = 16\n",
    "\n",
    "subtopic_embedding_layer = Embedding(num_embeddings=len(subtopic_to_index), embedding_dim=subtopic_embedding_dim)\n",
    "institution_embedding_layer = Embedding(num_embeddings=len(institution_to_index), embedding_dim=institution_embedding_dim)\n",
    "\n",
    "subtopic_embeddings = subtopic_embedding_layer(torch.tensor(subtopic_indices))\n",
    "institution_embeddings = institution_embedding_layer(torch.tensor(institution_indices))\n",
    "\n",
    "#Combine all the features (dropping git url)\n",
    "final_features = []\n",
    "\n",
    "for idx, (key, value) in enumerate(repository_dict.items()):\n",
    "    existing_embedding = torch.tensor(value[0])  # Existing embedding (e.g., value[0])\n",
    "    subtopic_emb = subtopic_embeddings[idx]      # Subtopic embedding\n",
    "    institution_emb = institution_embeddings[idx]# Institution embedding\n",
    "    topic_onehot = torch.tensor(topics_encoded[idx], dtype=torch.float)  # One-hot encoded topic\n",
    "\n",
    "    combined_features = torch.cat([existing_embedding, subtopic_emb, institution_emb, topic_onehot])\n",
    "    final_features.append(combined_features)\n",
    "\n",
    "final_features_tensor = torch.stack(final_features)\n",
    "np.save('data/final_features_tensor.npy', final_features_tensor.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd0cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the initial edge_index using citation relationships\n",
    "edge_index = []\n",
    "edge_weight = []  # To store edge weights\n",
    "\n",
    "# Create a mapping of repository IDs to indices\n",
    "node_to_index = {key: idx for idx, key in enumerate(repository_dict.keys())}\n",
    "\n",
    "# Build edge_index for official citation relationships\n",
    "for node_id, node_data in repository_dict.items():\n",
    "    source_idx = node_to_index[node_id]  # Index of the current repository\n",
    "    citations = node_data[1]  # Citation relationship array\n",
    "\n",
    "    for cited_repo in citations:\n",
    "        if cited_repo in node_to_index:  # Only add edges if the cited repo is in the dataset\n",
    "            target_idx = node_to_index[cited_repo]\n",
    "            edge_index.append([source_idx, target_idx])  # Directed edge: source -> target\n",
    "            edge_weight.append(1.0)  # Citation edge weight = 1 (strong connection)\n",
    "\n",
    "#Compute pairwise cosine similarity between repository embeddings\n",
    "embeddings = torch.tensor([value[0] for value in repository_dict.values()])  # Embedding matrix\n",
    "similarity_matrix = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "\n",
    "#Ensure that every node has at least K connections (citations + similarities)\n",
    "K = 3  # Minimum number of connections\n",
    "\n",
    "min_sim, max_sim = 0.57, 0.99\n",
    "for idx, (key, value) in enumerate(repository_dict.items()):\n",
    "    existing_connections = set([edge[1] for edge in edge_index if edge[0] == idx])  # Current connections\n",
    "\n",
    "    # Add more connections based on similarity if the node has fewer than K connections\n",
    "    if len(existing_connections) < K:\n",
    "        similarity_scores = similarity_matrix[idx]  # Similarity with all other repositories\n",
    "\n",
    "        # Get the indices of the top K most similar repositories (excluding already connected nodes)\n",
    "        sorted_similarities = torch.argsort(similarity_scores, descending=True)\n",
    "        # Add new connections based on similarity, but ignore self and already connected nodes\n",
    "        count = len(existing_connections)\n",
    "        for neighbor_idx in sorted_similarities:\n",
    "            if neighbor_idx != idx and neighbor_idx.item() not in existing_connections:\n",
    "                edge_index.append([idx, neighbor_idx.item()])\n",
    "                cosine_similarity_weight = 0 + ((similarity_scores[neighbor_idx] - min_sim) / (max_sim - min_sim)) * 0.8\n",
    "                edge_weight.append(cosine_similarity_weight)  # Use cosine similarity as weight\n",
    "                count += 1\n",
    "            if count >= K:\n",
    "                break\n",
    "\n",
    "if len(edge_index) > 0:\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weight = torch.tensor(edge_weight, dtype=torch.float)\n",
    "else:\n",
    "    raise ValueError(\"The edge_index is empty. Ensure citation relationships are correct.\")\n",
    "\n",
    "# Debugging: Print the constructed edge_index and edge weights\n",
    "# print(\"edge_index:\", edge_index)\n",
    "# print(\"edge_weight:\", edge_weight)\n",
    "np.save('data/edge_index.npy', edge_index.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddebffef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings require grad: True\n",
      "Edge index requires grad: No gradients\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5cb32eb4b8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m  \u001b[0;31m# Set number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}, Loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5cb32eb4b8e9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrastive_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "def contrastive_loss(embeddings, edge_index):\n",
    "    print(\"Embeddings require grad:\", embeddings.requires_grad)\n",
    "    print(\"Edge index requires grad:\", edge_index.requires_grad if edge_index.requires_grad else 'No gradients')\n",
    "\n",
    "    # Keep the embeddings as part of the computation graph\n",
    "    node_embeddings = embeddings[edge_index]\n",
    "    node_i, node_j = node_embeddings[0], node_embeddings[1]\n",
    "\n",
    "    # Positive pair similarity (for nodes with an edge between them)\n",
    "    pos_sim = F.cosine_similarity(node_i, node_j, dim=-1)\n",
    "\n",
    "    # Negative pair similarity (randomly sample unconnected nodes)\n",
    "    neg_sim = torch.mm(embeddings.detach(), embeddings.detach().t())  # No detaching; negative pairs will also track gradients\n",
    "\n",
    "    # Mask out similarities of nodes with edges (since we only want unconnected pairs for negatives)\n",
    "    neg_sim[edge_index[0], edge_index[1]] = float('-inf')  # Mask out connected pairs\n",
    "\n",
    "    # Use only the highest negative similarities (hard negative mining)\n",
    "    hardest_neg_sim = torch.max(neg_sim, dim=-1)[0]  # Max similarity for unconnected nodes\n",
    "\n",
    "    # Loss: maximize positive similarity, minimize negative similarity\n",
    "    pos_loss = (1 - pos_sim).mean()\n",
    "    neg_loss = hardest_neg_sim.mean()\n",
    "\n",
    "    return pos_loss + neg_loss\n",
    "\n",
    "# Step 2: Create a PyTorch Geometric Data object\n",
    "# final_features_tensor = the processed node features (from the previous step)\n",
    "data = Data(x=final_features_tensor, edge_index=edge_index)\n",
    "\n",
    "# Step 3: Define the GNN model using PyTorch Geometric\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)  # First GCN layer\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)  # Second GCN layer (output layer)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # First layer: Apply convolution and ReLU activation\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # Second layer: Another convolution (no activation needed)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Step 4: Instantiate the model and define optimizer and loss function\n",
    "in_channels = final_features_tensor.shape[1]  # Number of input features (from the processed feature vector)\n",
    "hidden_channels = 128  # Hidden dimension size (you can adjust this)\n",
    "out_channels = 128 # Output embedding size (you can adjust this)\n",
    "\n",
    "model = GCN(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 5: Training the model (unsupervised learning - using reconstruction loss or similar)\n",
    "# Define a simple training loop (this is an unsupervised example, using embeddings)\n",
    "\n",
    "def train():\n",
    "    global edge_index\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    model.train()\n",
    "\n",
    "    out = model(data)  # Forward pass\n",
    "    #print(\"Model output (embeddings) require grad:\", out.requires_grad)\n",
    "    edge_index = edge_index.detach() if edge_index.requires_grad else edge_index\n",
    "    loss = contrastive_loss(out, edge_index)\n",
    "    loss.backward(retain_graph=True)  # Backpropagate\n",
    "    optimizer.step()  # Update weights\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "# Step 6: Training Loop\n",
    "num_epochs = 100  # Set number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Step 7: Use the trained GNN model to get node embeddings\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    embeddings = model(data)  # Get embeddings for each node (repository)\n",
    "    print(\"Embeddings for each repository:\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57276f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
